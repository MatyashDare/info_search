{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import scipy\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = pd.read_csv('../corpora/corpus_ft_answers.csv')\n",
    "cols = [col for col in ft.columns if 'word' in col]\n",
    "ft = ft[cols].values\n",
    "answers_corpora = {'FastText': ft}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarity(sparse_matrix, query):\n",
    "    return np.dot(sparse_matrix, query.T).toarray()\n",
    "def get_cosine_similarity2(sparse_matrix, query):\n",
    "    return np.dot(sparse_matrix, query.T)\n",
    "\n",
    "\n",
    "def count_metric(method):\n",
    "    if method != 'corpus_ft':\n",
    "        anwers_matrix = sparse.load_npz(f'../corpora/{method}_answers.npz')\n",
    "        res_mat = get_cosine_similarity(anwers_matrix, questions_matrix)\n",
    "        \n",
    "        \n",
    "        \n",
    "    elif method == 'FastText:\n",
    "        \n",
    "        get_cosine_similarity2(answers_corpora[method], query)\n",
    "#         answers_matrix = pd.read_csv('../corpora/corpus_ft_answers.csv')\n",
    "#         cols = [col for col in answers_matrix.columns if 'word' in col]\n",
    "#         res_mat = get_cosine_similarity2(answers_matrix[cols].values, questions_matrix[cols].values)\n",
    "    return np.argsort(-res_mat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gensim\n",
    "from gensim.models.wrappers import FastText\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import streamlit as st\n",
    "from pymystem3 import Mystem\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n",
    "import scipy\n",
    "from scipy import sparse\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import time\n",
    "\n",
    "# mystem = Mystem()\n",
    "\n",
    "# bert_tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny\")\n",
    "# bert_model = AutoModel.from_pretrained(\"cointegrated/rubert-tiny\")\n",
    "# model_ft = gensim.models.KeyedVectors.load('../vectorizers/araneum_none_fasttextcbow_300_5_2018.model')\n",
    "# df = pd.read_csv('../corpora/qa.csv')\n",
    "\n",
    "def preprocess_line(text: str) -> str:\n",
    "    # убираем пунктуацию, оставляем только дефисы\n",
    "    no_punct = re.sub('[,\\?\\!\\.\"\\:]|[a-zA-Z]+', '', ''.join(text))\n",
    "    # токенизируем и лемматизируем текст, приводим к нижнему регистру\n",
    "    lem_words = mystem.lemmatize(text.lower())\n",
    "    ans = ' '.join([w for w in lem_words if w.isalpha()])\n",
    "    if ans == \" \":\n",
    "        return 'пустой текст'\n",
    "    elif ans == '':\n",
    "        return 'пустой текст'\n",
    "    else:\n",
    "        return re.sub('\\n', '', ans)\n",
    "\n",
    "def cosine_similarity_matrix_query(sparse_matrix, query):\n",
    "    return np.dot(sparse_matrix, query.T).toarray()\n",
    "\n",
    "def vec_normalization(vec):\n",
    "    return vec / np.linalg.norm(vec)\n",
    "\n",
    "def make_ft_embedding(line:str, model_ft):\n",
    "    emb_list = []\n",
    "    for word in line.split():\n",
    "        emb_list .append(model_ft[word])\n",
    "    emb_list = vec_normalization(np.array(emb_list))\n",
    "    return emb_list.mean(axis=0)\n",
    "\n",
    "def cs_FastText(query, corpus_ft, cols, model_ft):\n",
    "    scores = cosine_similarity(make_ft_embedding(query, model_ft).reshape((1,300)), corpus_ft[cols].as_matrix())[0]\n",
    "    argx = np.argsort(scores)[::-1]\n",
    "    return df['answers'][argx.ravel()]\n",
    "\n",
    "def cs_CountVectorizer(query, count_vectorizer, sparse_matrix):\n",
    "    query = count_vectorizer.transform([query])\n",
    "    scores = cosine_similarity_matrix_query(sparse_matrix, query)\n",
    "    argx = np.argsort(scores, axis=0)[::-1]\n",
    "    return df['answers'][argx.ravel()]\n",
    "\n",
    "\n",
    "def cs_TfidfVectorizer(query, tfidf_vectorizer, sparse_matrix):\n",
    "    query = tfidf_vectorizer.transform([query])\n",
    "    scores = cosine_similarity_matrix_query(sparse_matrix, query)\n",
    "    argx = np.argsort(scores, axis=0)[::-1]\n",
    "    return df['answers'][argx.ravel()]\n",
    "\n",
    "\n",
    "def cs_BM25(query, count_vectorizer, sparse_matrix):\n",
    "    query = count_vectorizer.transform([query])\n",
    "    scores = cosine_similarity_matrix_query(sparse_matrix, query)\n",
    "    argx = np.argsort(scores, axis=0)[::-1]\n",
    "    return df['answers'][argx.ravel()]\n",
    "\n",
    "def make_bert_embedding(query, bert_model, bert_tokenizer):\n",
    "    embeddings = embed_bert_cls(query, bert_model, bert_tokenizer)\n",
    "    return sparse.csr_matrix(embeddings)\n",
    "\n",
    "\n",
    "def cs_BERT(query, sparse_matrix, bert_model, bert_tokenizer):\n",
    "    query = make_bert_embedding(query, bert_model, bert_tokenizer)\n",
    "    scores = cosine_similarity_matrix_query(sparse_matrix, query)\n",
    "    argx = np.argsort(scores, axis=0)[::-1]\n",
    "    return df['answers'][argx.ravel()]\n",
    "\n",
    "def embed_bert_cls(text, model, tokenizer):\n",
    "    t = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**{k: v.to(model.device) for k, v in t.items()})\n",
    "    embeddings = model_output.last_hidden_state[:, 0, :]\n",
    "    embeddings = torch.nn.functional.normalize(embeddings)\n",
    "    return embeddings[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     st.title('это поисковик Жени Егоровой')\n",
    "#     st.header('он норм')\n",
    "#     st.subheader('но несет фигню')\n",
    "#     st.write('попробуйте')\n",
    "    query = st.text_area('Введите ваш запрос')\n",
    "    choice = st.radio('Выберите метод, по которому будет происходить поиск',\n",
    "                              ['CountVectorizer', 'TfidfVectorizer', 'BM25', 'FastText', 'BERT'])\n",
    "    if st.button('искать'):\n",
    "        start_time = time.time()\n",
    "\n",
    "def query_return(query, choice):\n",
    "    if choice == 'CountVectorizer':\n",
    "#         count_vectorizer = pickle.load(open('../vectorizers/count_vectorizer.pickle', 'rb'))\n",
    "#         sparse_matrix = sparse.load_npz('../corpora/count_vectorizer_answers.npz')\n",
    "        count_vectorizer = d['count_vectorizer']\n",
    "        sparse_matrix = d['sparse_matrix_count_vectorizer']\n",
    "        ans_ranged = cs_CountVectorizer(query, count_vectorizer, sparse_matrix)\n",
    "    elif choice == \"TfidfVectorizer\":\n",
    "#         tfidf_vectorizer = pickle.load(open('../vectorizers/tfidf_vectorizer.pickle', 'rb'))\n",
    "#         sparse_matrix = sparse.load_npz('../corpora/tfidf_vectorizer_answers.npz')\n",
    "        tfidf_vectorizer = d['tfidf_vectorizer']\n",
    "        sparse_matrix = d['sparse_matrix_tfidf_vectorizer']\n",
    "        ans_ranged = cs_TfidfVectorizer(query, tfidf_vectorizer, sparse_matrix)\n",
    "    elif choice == \"BM25\":\n",
    "#         count_vectorizer = pickle.load(open('../vectorizers/count_vectorizer.pickle', 'rb'))\n",
    "#         sparse_matrix = sparse.load_npz('../corpora/BM25_answers.npz')\n",
    "        count_vectorizer = d['count_vectorizer']\n",
    "        sparse_matrix = d['sparse_matrix_BM25']\n",
    "        ans_ranged = cs_BM25(query, count_vectorizer, sparse_matrix)\n",
    "    elif choice == \"FastText\":\n",
    "        corpus_ft = d['corpus_ft']\n",
    "        cols = d['cols']\n",
    "        model_ft = d['model_ft']\n",
    "#         corpus_ft = pd.read_csv('../corpora/corpus_ft_answers.csv')\n",
    "#         cols = [col for col in corpus_ft.columns if 'word' in col]\n",
    "        ans_ranged = cs_FastText(query, corpus_ft, cols, model_ft)\n",
    "    elif choice == \"BERT\":\n",
    "        sparse_matrix = d['sparse_matrix_BERT']\n",
    "#         sparse_matrix = sparse.load_npz('../corpora/BERT_answers.npz')\n",
    "        bert_model = d['bert_model']\n",
    "        bert_tokenizer = d['bert_tokenizer']\n",
    "        ans_ranged = cs_BERT(query, sparse_matrix, bert_model, bert_tokenizer)\n",
    "    return ans_ranged[:5].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-326013e96544>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mquery_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'не любит'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CountVectorizer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-ab0780529671>\u001b[0m in \u001b[0;36mquery_return\u001b[0;34m(query, choice)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#         count_vectorizer = pickle.load(open('../vectorizers/count_vectorizer.pickle', 'rb'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#         sparse_matrix = sparse.load_npz('../corpora/count_vectorizer_answers.npz')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mcount_vectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count_vectorizer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0msparse_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sparse_matrix_count_vectorizer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mans_ranged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcs_CountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_vectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "query_return('не любит', 'CountVectorizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Не будет.',\n",
       " 'Это не с ней. А с Вами что-то не так.',\n",
       " 'не уважает и не любит',\n",
       " 'нет, не прощала и не буду',\n",
       " 'Я не хочу))']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_return('не любит', 'Tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['не относись', 'не известно', 'Не судьба', 'Не уверен', 'Не отпускай']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_return('не любит', 'BM25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Не любит.',\n",
       " 'не с любыми',\n",
       " 'не дружелюбие',\n",
       " 'не уважает и не любит',\n",
       " 'такое не бывает']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_return('не любит', 'BERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:52: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['не уважает и не любит',\n",
       " 'Значит не любит или боится.',\n",
       " 'Я не ревнивый.',\n",
       " 'Кот не любовник, не истери.',\n",
       " 'не с любыми']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_return('не любит', 'FastText')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  👋 \u001b[1mWelcome to Streamlit!\u001b[0m\n",
      "\n",
      "  If you're one of our development partners or you're interested in getting\n",
      "  personal technical support or Streamlit updates, please enter your email\n",
      "  address below. Otherwise, you may leave the field blank.\n",
      "\n",
      "  \u001b[34mEmail: \u001b[0m^C\n",
      "2021-10-20 10:50:33.786 \n"
     ]
    }
   ],
   "source": [
    "!streamlit run myfile.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@st.cache(allow_output_mutation=True)\n",
    "def data_loader():\n",
    "    d = {}\n",
    "    bert_tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny\")\n",
    "    bert_model = AutoModel.from_pretrained(\"cointegrated/rubert-tiny\")\n",
    "    model_ft = gensim.models.KeyedVectors.load('../vectorizers/araneum_none_fasttextcbow_300_5_2018.model')\n",
    "    df = pd.read_csv('../corpora/qa.csv')\n",
    "    d['bert_tokenizer'] = bert_tokenizer\n",
    "    d['bert_model'] = bert_model\n",
    "    d['model_ft'] = model_ft\n",
    "    d['df'] = df\n",
    "    d['mystem'] = Mystem()\n",
    "    \n",
    "    count_vectorizer = pickle.load(open('../vectorizers/count_vectorizer.pickle', 'rb'))\n",
    "    sparse_matrix_count_vectorizer = sparse.load_npz('../corpora/count_vectorizer_answers.npz')\n",
    "    d['count_vectorizer'] = count_vectorizer\n",
    "    d['sparse_matrix_count_vectorizer'] = sparse_matrix_count_vectorizer\n",
    "    sparse_matrix_BM25 = sparse.load_npz('../corpora/BM25_answers.npz')\n",
    "    d['sparse_matrix_BM25'] = sparse_matrix_BM25\n",
    "    \n",
    "    tfidf_vectorizer = pickle.load(open('../vectorizers/tfidf_vectorizer.pickle', 'rb'))\n",
    "    sparse_matrix_tfidf_vectorizer = sparse.load_npz('../corpora/tfidf_vectorizer_answers.npz')\n",
    "    d['tfidf_vectorizer'] = tfidf_vectorizer\n",
    "    d['sparse_matrix_tfidf_vectorizer'] = sparse_matrix_tfidf_vectorizer\n",
    "    \n",
    "    corpus_ft = pd.read_csv('../corpora/corpus_ft_answers.csv')\n",
    "    cols = [col for col in corpus_ft.columns if 'word' in col]\n",
    "    d['corpus_ft'] = corpus_ft\n",
    "    d['cols'] = cols\n",
    "    \n",
    "    sparse_matrix_BERT = sparse.load_npz('../corpora/BERT_answers.npz')\n",
    "    d['sparse_matrix_BERT'] = sparse_matrix_BERT\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = data_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-20 11:01:15.838 loading Word2VecKeyedVectors object from ../vectorizers/araneum_none_fasttextcbow_300_5_2018.model\n",
      "2021-10-20 11:01:17.564 loading vectors from ../vectorizers/araneum_none_fasttextcbow_300_5_2018.model.vectors.npy with mmap=None\n",
      "2021-10-20 11:01:17.824 loading vectors_ngrams from ../vectorizers/araneum_none_fasttextcbow_300_5_2018.model.vectors_ngrams.npy with mmap=None\n",
      "2021-10-20 11:01:20.755 loading vectors_vocab from ../vectorizers/araneum_none_fasttextcbow_300_5_2018.model.vectors_vocab.npy with mmap=None\n",
      "2021-10-20 11:01:21.084 setting ignored attribute vectors_vocab_norm to None\n",
      "2021-10-20 11:01:21.087 setting ignored attribute vectors_ngrams_norm to None\n",
      "2021-10-20 11:01:21.088 setting ignored attribute vectors_norm to None\n",
      "2021-10-20 11:01:21.089 setting ignored attribute buckets_word to None\n",
      "2021-10-20 11:01:21.089 loaded ../vectorizers/araneum_none_fasttextcbow_300_5_2018.model\n"
     ]
    }
   ],
   "source": [
    "model_ft = gensim.models.KeyedVectors.load('../vectorizers/araneum_none_fasttextcbow_300_5_2018.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         st.markdown(\"--- _%s   секунд на поиск_ ---\" % (ans_time))\n",
    "#     choice = st.radio('Выберите метод, по которому будет происходить поиск',\n",
    "#                               ['CountVectorizer', 'TfidfVectorizer', 'BM25', 'FastText', 'BERT'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
